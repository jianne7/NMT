{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4faff66-ec30-4894-bfa6-257b74b917ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from tqdm import tqdm\n",
    "from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import DataCollatorWithPadding\n",
    "from transformers import AdamW\n",
    "\n",
    "from dataset import TranslationDataset\n",
    "import warnings\n",
    "import gc\n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb522e1e-92d9-489e-833f-3a9ea3b324ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2effd49-ab4c-4b5a-a67c-9cd8983e8730",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_path = 'voiceprint/m2m100_418M'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7d71c9c-ce2c-40c1-8658-87a951f77795",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M2M100ForConditionalGeneration(\n",
       "  (model): M2M100Model(\n",
       "    (shared): Embedding(128112, 1024, padding_idx=1)\n",
       "    (encoder): M2M100Encoder(\n",
       "      (embed_tokens): Embedding(128112, 1024, padding_idx=1)\n",
       "      (embed_positions): M2M100SinusoidalPositionalEmbedding()\n",
       "      (layers): ModuleList(\n",
       "        (0): M2M100EncoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): M2M100EncoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): M2M100EncoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): M2M100EncoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): M2M100EncoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): M2M100EncoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (6): M2M100EncoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (7): M2M100EncoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (8): M2M100EncoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (9): M2M100EncoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (10): M2M100EncoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (11): M2M100EncoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): M2M100Decoder(\n",
       "      (embed_tokens): Embedding(128112, 1024, padding_idx=1)\n",
       "      (embed_positions): M2M100SinusoidalPositionalEmbedding()\n",
       "      (layers): ModuleList(\n",
       "        (0): M2M100DecoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): M2M100DecoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): M2M100DecoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): M2M100DecoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): M2M100DecoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): M2M100DecoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (6): M2M100DecoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (7): M2M100DecoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (8): M2M100DecoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (9): M2M100DecoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (10): M2M100DecoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (11): M2M100DecoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=128112, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teacher_model = M2M100ForConditionalGeneration.from_pretrained(model_path)\n",
    "teacher_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97abd74f-ce01-4cd5-9c3a-d4b445e369ce",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at voiceprint/m2m100_418M were not used when initializing M2M100ForConditionalGeneration: ['model.decoder.layers.10.self_attn.q_proj.bias', 'model.encoder.layers.11.fc1.bias', 'model.encoder.layers.10.self_attn.k_proj.weight', 'model.decoder.layers.7.encoder_attn.k_proj.bias', 'model.decoder.layers.6.fc1.bias', 'model.decoder.layers.11.encoder_attn.q_proj.bias', 'model.encoder.layers.8.self_attn.q_proj.bias', 'model.decoder.layers.10.final_layer_norm.weight', 'model.decoder.layers.11.self_attn.out_proj.bias', 'model.encoder.layers.7.final_layer_norm.weight', 'model.decoder.layers.10.encoder_attn_layer_norm.weight', 'model.encoder.layers.11.self_attn.k_proj.bias', 'model.decoder.layers.7.self_attn.v_proj.bias', 'model.encoder.layers.6.self_attn.v_proj.bias', 'model.decoder.layers.8.self_attn_layer_norm.bias', 'model.decoder.layers.11.self_attn.q_proj.bias', 'model.decoder.layers.11.final_layer_norm.bias', 'model.encoder.layers.7.self_attn_layer_norm.weight', 'model.decoder.layers.11.self_attn.k_proj.weight', 'model.decoder.layers.8.encoder_attn.v_proj.weight', 'model.decoder.layers.10.self_attn.k_proj.weight', 'model.decoder.layers.10.encoder_attn.q_proj.bias', 'model.encoder.layers.9.self_attn.out_proj.weight', 'model.encoder.layers.8.self_attn.out_proj.weight', 'model.encoder.layers.10.self_attn.v_proj.weight', 'model.decoder.layers.7.self_attn.q_proj.bias', 'model.encoder.layers.7.self_attn.v_proj.bias', 'model.decoder.layers.6.self_attn.k_proj.weight', 'model.decoder.layers.11.self_attn_layer_norm.weight', 'model.encoder.layers.7.self_attn.k_proj.weight', 'model.encoder.layers.6.fc2.bias', 'model.decoder.layers.8.encoder_attn.k_proj.bias', 'model.decoder.layers.6.self_attn_layer_norm.weight', 'model.decoder.layers.6.fc1.weight', 'model.decoder.layers.7.fc2.bias', 'model.decoder.layers.10.encoder_attn.out_proj.weight', 'model.decoder.layers.7.self_attn_layer_norm.bias', 'model.decoder.layers.11.encoder_attn.v_proj.bias', 'model.decoder.layers.6.self_attn.k_proj.bias', 'model.decoder.layers.8.encoder_attn.q_proj.bias', 'model.encoder.layers.9.fc2.bias', 'model.decoder.layers.9.fc2.weight', 'model.encoder.layers.8.final_layer_norm.weight', 'model.decoder.layers.8.encoder_attn_layer_norm.bias', 'model.encoder.layers.8.self_attn.v_proj.bias', 'model.decoder.layers.9.self_attn.k_proj.weight', 'model.encoder.layers.7.fc2.bias', 'model.decoder.layers.9.encoder_attn_layer_norm.bias', 'model.decoder.layers.9.self_attn.out_proj.weight', 'model.decoder.layers.7.encoder_attn.q_proj.weight', 'model.decoder.layers.7.encoder_attn.q_proj.bias', 'model.encoder.layers.7.self_attn.out_proj.bias', 'model.encoder.layers.11.self_attn_layer_norm.bias', 'model.encoder.layers.6.self_attn_layer_norm.bias', 'model.decoder.layers.11.encoder_attn.out_proj.weight', 'model.decoder.layers.10.final_layer_norm.bias', 'model.encoder.layers.9.self_attn.q_proj.bias', 'model.decoder.layers.8.fc2.weight', 'model.decoder.layers.8.self_attn.q_proj.weight', 'model.encoder.layers.11.fc1.weight', 'model.decoder.layers.9.self_attn_layer_norm.bias', 'model.encoder.layers.9.final_layer_norm.bias', 'model.decoder.layers.7.self_attn.v_proj.weight', 'model.decoder.layers.6.encoder_attn.k_proj.weight', 'model.decoder.layers.10.self_attn.v_proj.weight', 'model.decoder.layers.11.final_layer_norm.weight', 'model.encoder.layers.10.self_attn_layer_norm.weight', 'model.encoder.layers.6.self_attn.q_proj.bias', 'model.decoder.layers.8.encoder_attn.k_proj.weight', 'model.encoder.layers.6.self_attn_layer_norm.weight', 'model.encoder.layers.11.self_attn.q_proj.bias', 'model.encoder.layers.9.fc1.bias', 'model.decoder.layers.11.encoder_attn.k_proj.weight', 'model.decoder.layers.7.encoder_attn_layer_norm.bias', 'model.encoder.layers.6.self_attn.out_proj.weight', 'model.encoder.layers.10.self_attn.q_proj.bias', 'model.decoder.layers.9.self_attn_layer_norm.weight', 'model.decoder.layers.6.encoder_attn_layer_norm.weight', 'model.decoder.layers.10.encoder_attn.v_proj.weight', 'model.decoder.layers.7.self_attn.out_proj.weight', 'model.decoder.layers.9.self_attn.v_proj.weight', 'model.encoder.layers.7.fc1.bias', 'model.encoder.layers.8.self_attn.out_proj.bias', 'model.decoder.layers.9.self_attn.q_proj.bias', 'model.decoder.layers.10.fc1.bias', 'model.decoder.layers.9.fc1.weight', 'model.encoder.layers.7.fc1.weight', 'model.encoder.layers.11.self_attn.v_proj.bias', 'model.encoder.layers.7.self_attn.v_proj.weight', 'model.decoder.layers.7.encoder_attn.v_proj.bias', 'model.decoder.layers.9.self_attn.out_proj.bias', 'model.encoder.layers.6.fc1.bias', 'model.encoder.layers.10.final_layer_norm.bias', 'model.decoder.layers.10.encoder_attn.k_proj.weight', 'model.decoder.layers.7.encoder_attn_layer_norm.weight', 'model.decoder.layers.7.fc1.weight', 'model.encoder.layers.10.fc1.weight', 'model.encoder.layers.6.fc2.weight', 'model.encoder.layers.11.self_attn.out_proj.weight', 'model.decoder.layers.8.fc1.bias', 'model.encoder.layers.7.self_attn.q_proj.bias', 'model.encoder.layers.9.fc1.weight', 'model.encoder.layers.11.self_attn.out_proj.bias', 'model.decoder.layers.9.encoder_attn.v_proj.weight', 'model.decoder.layers.7.fc2.weight', 'model.decoder.layers.11.fc1.weight', 'model.decoder.layers.7.self_attn.q_proj.weight', 'model.encoder.layers.9.fc2.weight', 'model.decoder.layers.9.encoder_attn.v_proj.bias', 'model.decoder.layers.10.self_attn.v_proj.bias', 'model.encoder.layers.11.fc2.bias', 'model.decoder.layers.6.self_attn.q_proj.weight', 'model.decoder.layers.10.fc1.weight', 'model.decoder.layers.10.self_attn.q_proj.weight', 'model.decoder.layers.11.self_attn.v_proj.bias', 'model.decoder.layers.6.final_layer_norm.bias', 'model.decoder.layers.6.fc2.weight', 'model.encoder.layers.8.self_attn_layer_norm.bias', 'model.decoder.layers.8.self_attn.out_proj.weight', 'model.decoder.layers.8.self_attn.out_proj.bias', 'model.decoder.layers.9.self_attn.v_proj.bias', 'model.encoder.layers.11.self_attn.v_proj.weight', 'model.decoder.layers.9.fc2.bias', 'model.decoder.layers.7.encoder_attn.out_proj.weight', 'model.encoder.layers.10.fc1.bias', 'model.decoder.layers.6.encoder_attn.v_proj.weight', 'model.decoder.layers.8.encoder_attn.out_proj.bias', 'model.decoder.layers.11.encoder_attn.v_proj.weight', 'model.encoder.layers.8.self_attn_layer_norm.weight', 'model.decoder.layers.11.self_attn.k_proj.bias', 'model.decoder.layers.10.self_attn_layer_norm.weight', 'model.decoder.layers.8.self_attn.k_proj.bias', 'model.decoder.layers.8.self_attn.k_proj.weight', 'model.decoder.layers.8.encoder_attn.q_proj.weight', 'model.decoder.layers.6.encoder_attn.out_proj.weight', 'model.decoder.layers.10.fc2.weight', 'model.decoder.layers.9.self_attn.k_proj.bias', 'model.decoder.layers.8.encoder_attn.out_proj.weight', 'model.decoder.layers.7.self_attn_layer_norm.weight', 'model.decoder.layers.7.self_attn.k_proj.bias', 'model.encoder.layers.9.self_attn.k_proj.weight', 'model.encoder.layers.9.self_attn.v_proj.weight', 'model.encoder.layers.11.self_attn.k_proj.weight', 'model.decoder.layers.9.encoder_attn.k_proj.bias', 'model.decoder.layers.11.fc2.bias', 'model.encoder.layers.6.self_attn.q_proj.weight', 'model.encoder.layers.10.self_attn.q_proj.weight', 'model.decoder.layers.6.self_attn.q_proj.bias', 'model.encoder.layers.10.self_attn.k_proj.bias', 'model.decoder.layers.9.encoder_attn.q_proj.weight', 'model.encoder.layers.10.self_attn_layer_norm.bias', 'model.decoder.layers.9.self_attn.q_proj.weight', 'model.encoder.layers.8.fc1.bias', 'model.encoder.layers.7.self_attn_layer_norm.bias', 'model.decoder.layers.9.encoder_attn.out_proj.bias', 'model.encoder.layers.8.fc2.weight', 'model.encoder.layers.9.final_layer_norm.weight', 'model.encoder.layers.8.self_attn.q_proj.weight', 'model.encoder.layers.8.self_attn.v_proj.weight', 'model.decoder.layers.8.self_attn.q_proj.bias', 'model.decoder.layers.8.self_attn_layer_norm.weight', 'model.encoder.layers.11.final_layer_norm.bias', 'model.decoder.layers.6.fc2.bias', 'model.encoder.layers.8.final_layer_norm.bias', 'model.decoder.layers.6.self_attn.v_proj.bias', 'model.decoder.layers.7.fc1.bias', 'model.encoder.layers.10.fc2.bias', 'model.decoder.layers.8.fc2.bias', 'model.encoder.layers.9.self_attn_layer_norm.bias', 'model.encoder.layers.9.self_attn.k_proj.bias', 'model.encoder.layers.7.self_attn.q_proj.weight', 'model.decoder.layers.8.self_attn.v_proj.weight', 'model.decoder.layers.6.encoder_attn.k_proj.bias', 'model.decoder.layers.7.final_layer_norm.weight', 'model.decoder.layers.11.self_attn.out_proj.weight', 'model.decoder.layers.7.self_attn.k_proj.weight', 'model.encoder.layers.8.fc2.bias', 'model.decoder.layers.11.fc1.bias', 'model.encoder.layers.10.self_attn.out_proj.bias', 'model.decoder.layers.7.final_layer_norm.bias', 'model.encoder.layers.7.self_attn.k_proj.bias', 'model.encoder.layers.9.self_attn.v_proj.bias', 'model.encoder.layers.11.fc2.weight', 'model.decoder.layers.6.self_attn.out_proj.weight', 'model.decoder.layers.9.encoder_attn.k_proj.weight', 'model.decoder.layers.6.final_layer_norm.weight', 'model.decoder.layers.8.final_layer_norm.bias', 'model.encoder.layers.7.self_attn.out_proj.weight', 'model.decoder.layers.10.self_attn.k_proj.bias', 'model.encoder.layers.10.self_attn.v_proj.bias', 'model.encoder.layers.11.self_attn_layer_norm.weight', 'model.decoder.layers.11.self_attn_layer_norm.bias', 'model.decoder.layers.6.self_attn.v_proj.weight', 'model.decoder.layers.8.encoder_attn_layer_norm.weight', 'model.decoder.layers.10.self_attn_layer_norm.bias', 'model.decoder.layers.9.final_layer_norm.bias', 'model.decoder.layers.8.self_attn.v_proj.bias', 'model.encoder.layers.6.self_attn.out_proj.bias', 'model.decoder.layers.7.encoder_attn.out_proj.bias', 'model.decoder.layers.9.final_layer_norm.weight', 'model.decoder.layers.10.encoder_attn_layer_norm.bias', 'model.decoder.layers.6.encoder_attn.q_proj.bias', 'model.decoder.layers.11.encoder_attn.k_proj.bias', 'model.encoder.layers.6.self_attn.k_proj.bias', 'model.encoder.layers.10.self_attn.out_proj.weight', 'model.encoder.layers.9.self_attn.q_proj.weight', 'model.encoder.layers.6.self_attn.k_proj.weight', 'model.encoder.layers.6.self_attn.v_proj.weight', 'model.encoder.layers.8.self_attn.k_proj.bias', 'model.decoder.layers.10.encoder_attn.out_proj.bias', 'model.encoder.layers.8.self_attn.k_proj.weight', 'model.encoder.layers.6.fc1.weight', 'model.decoder.layers.11.encoder_attn.q_proj.weight', 'model.decoder.layers.6.self_attn.out_proj.bias', 'model.decoder.layers.11.encoder_attn_layer_norm.bias', 'model.decoder.layers.10.encoder_attn.v_proj.bias', 'model.decoder.layers.8.fc1.weight', 'model.decoder.layers.9.fc1.bias', 'model.encoder.layers.7.final_layer_norm.bias', 'model.encoder.layers.9.self_attn_layer_norm.weight', 'model.encoder.layers.9.self_attn.out_proj.bias', 'model.decoder.layers.7.self_attn.out_proj.bias', 'model.decoder.layers.6.encoder_attn.q_proj.weight', 'model.decoder.layers.7.encoder_attn.k_proj.weight', 'model.decoder.layers.11.encoder_attn_layer_norm.weight', 'model.decoder.layers.9.encoder_attn.q_proj.bias', 'model.decoder.layers.10.fc2.bias', 'model.encoder.layers.7.fc2.weight', 'model.decoder.layers.6.encoder_attn_layer_norm.bias', 'model.decoder.layers.6.encoder_attn.v_proj.bias', 'model.encoder.layers.8.fc1.weight', 'model.decoder.layers.7.encoder_attn.v_proj.weight', 'model.encoder.layers.11.final_layer_norm.weight', 'model.decoder.layers.11.self_attn.v_proj.weight', 'model.decoder.layers.8.encoder_attn.v_proj.bias', 'model.decoder.layers.10.self_attn.out_proj.weight', 'model.decoder.layers.11.fc2.weight', 'model.decoder.layers.10.encoder_attn.k_proj.bias', 'model.encoder.layers.11.self_attn.q_proj.weight', 'model.decoder.layers.10.self_attn.out_proj.bias', 'model.decoder.layers.8.final_layer_norm.weight', 'model.decoder.layers.6.encoder_attn.out_proj.bias', 'model.encoder.layers.6.final_layer_norm.bias', 'model.decoder.layers.10.encoder_attn.q_proj.weight', 'model.decoder.layers.11.encoder_attn.out_proj.bias', 'model.encoder.layers.6.final_layer_norm.weight', 'model.decoder.layers.9.encoder_attn_layer_norm.weight', 'model.encoder.layers.10.fc2.weight', 'model.decoder.layers.9.encoder_attn.out_proj.weight', 'model.encoder.layers.10.final_layer_norm.weight', 'model.decoder.layers.6.self_attn_layer_norm.bias', 'model.decoder.layers.11.self_attn.q_proj.weight']\n",
      "- This IS expected if you are initializing M2M100ForConditionalGeneration from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing M2M100ForConditionalGeneration from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "M2M100ForConditionalGeneration(\n",
       "  (model): M2M100Model(\n",
       "    (shared): Embedding(128112, 1024, padding_idx=1)\n",
       "    (encoder): M2M100Encoder(\n",
       "      (embed_tokens): Embedding(128112, 1024, padding_idx=1)\n",
       "      (embed_positions): M2M100SinusoidalPositionalEmbedding()\n",
       "      (layers): ModuleList(\n",
       "        (0): M2M100EncoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): M2M100EncoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): M2M100EncoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): M2M100EncoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): M2M100EncoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): M2M100EncoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): M2M100Decoder(\n",
       "      (embed_tokens): Embedding(128112, 1024, padding_idx=1)\n",
       "      (embed_positions): M2M100SinusoidalPositionalEmbedding()\n",
       "      (layers): ModuleList(\n",
       "        (0): M2M100DecoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): M2M100DecoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): M2M100DecoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): M2M100DecoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): M2M100DecoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): M2M100DecoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=128112, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_model = M2M100ForConditionalGeneration.from_pretrained(model_path, encoder_layers=6, decoder_layers=6)\n",
    "student_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adb40605-8dfb-4863-b629-c378334aa8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6da64297-315b-40b6-a29b-609e3b140735",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(data, pad_id, max_len):\n",
    "    padded_data = list(map(lambda x : torch.cat([x, torch.tensor([pad_id] * (max_len - len(x)))]), data))\n",
    "    return padded_data\n",
    "\n",
    "def collate_fn_translation(batch):\n",
    "    features = {}\n",
    "\n",
    "    input_ids = [torch.LongTensor(item['input_ids']) for item in batch]\n",
    "    max_len_input_ids = max(list(map(lambda x: len(x), input_ids)))\n",
    "    input_ids_padded = pad(input_ids, pad_id=1, max_len=max_len_input_ids)\n",
    "    features['input_ids'] = torch.stack(input_ids_padded, dim=0).type(torch.LongTensor)\n",
    "    # print(features)\n",
    "\n",
    "    attention_mask = [torch.Tensor(item['attention_mask']) for item in batch]\n",
    "    max_len_attention_mask = max(list(map(lambda x: len(x), attention_mask)))\n",
    "    attention_mask_padded = pad(attention_mask, pad_id=0, max_len=max_len_attention_mask)\n",
    "    features['attention_mask'] = torch.stack(attention_mask_padded, dim=0).type(torch.Tensor)\n",
    "    # print(features)\n",
    "    \n",
    "    labels = [torch.LongTensor(item['labels']) for item in batch]\n",
    "    max_len_labels = max(list(map(lambda x: len(x), labels)))\n",
    "    labels_padded = pad(labels, pad_id=-100, max_len=max_len_labels)\n",
    "    # features['labels'] = torch.stack(labels_padded, dim=0).type(torch.LongTensor)\n",
    "    features['labels'] = torch.stack(labels_padded, dim=0).type(torch.LongTensor)\n",
    "\n",
    "    # print(features)\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe7f0c39-e88d-4d10-b7a9-8990a3af8bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.metrics import bleu_score\n",
    "\n",
    "def evaluate(model, tokenizer, device):\n",
    "    # train_dataset = TranslationDataset(file_path='data/sns100.csv',\n",
    "    #                                     mode='train',\n",
    "    #                                     tokenizer=tokenizer)\n",
    "    # eval_dataloader = DataLoader(train_dataset, \n",
    "    #                              shuffle=False,\n",
    "    #                              batch_size=1, \n",
    "    #                              collate_fn=collate_fn_translation)\n",
    "    \n",
    "    dataset = TranslationDataset(file_path='data/sns100.csv',\n",
    "                                 tokenizer=tokenizer)\n",
    "    dataloader = DataLoader(dataset, \n",
    "                            shuffle=False,\n",
    "                            batch_size=1, \n",
    "                            collate_fn=collate_fn_translation)\n",
    "\n",
    "    bleu_scores = []\n",
    "    model.eval()\n",
    "    for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "        ref_text = tokenizer.batch_decode(batch['labels'], skip_special_tokens=True)\n",
    "        \n",
    "        del batch['labels']\n",
    "        generated_tokens = model.generate(**batch, forced_bos_token_id=tokenizer.get_lang_id(\"en\"), num_beams=1)\n",
    "        translated_text = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
    "        \n",
    "        # print(f\"ref: {ref_text}\")\n",
    "        # print(f\"hyp: {translated_text}\")\n",
    "\n",
    "        candi = translated_text[0].split(' ')\n",
    "        ref = ref_text[0].split(' ')\n",
    "    \n",
    "        bscore = bleu_score([candi], [[ref]], max_n=1, weights=[1])\n",
    "        # print(f'blue_score : {bscore}')\n",
    "        bleu_scores.append(bscore)\n",
    "        #break\n",
    "        \n",
    "    results = np.mean(bleu_scores)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def train_teacher(num_epochs, device, teacher_model, tokenizer):\n",
    "    # device = torch.device('cpu')\n",
    "    # teacher_model = model.to(device)\n",
    "    # #criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "    train_dataset = TranslationDataset(file_path='data/ko2en_travel_1_training_Bleu_Grouge.json',\n",
    "                        mode='train',\n",
    "                        tokenizer=tokenizer)\n",
    "\n",
    "    train_dataloader = DataLoader(\n",
    "            dataset=train_dataset, \n",
    "            batch_size=2,\n",
    "            shuffle=True,\n",
    "            #num_workers=1,\n",
    "            collate_fn=collate_fn_translation\n",
    "        )\n",
    "\n",
    "    num_epochs = num_epochs\n",
    "    num_training_steps = num_epochs * len(train_dataloader)\n",
    "    progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        teacher_model.train()\n",
    "        losses = []\n",
    "\n",
    "        pbar = tqdm(train_dataloader, total=len(train_dataloader), position=0, leave=True, desc=f'Epoch {epoch}')\n",
    "        for batch in train_dataloader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            progress_bar.update(1)\n",
    "            # break\n",
    "        # break\n",
    "\n",
    "        try:\n",
    "            avg_loss = sum(losses) / len(losses)\n",
    "        except ZeroDivisionError:\n",
    "            avg_loss = 0\n",
    "        acc = evaluate(teacher_model, tokenizer, device)\n",
    "        print(f'Loss:{avg_loss:.2f}\\tBleu:{acc:.2f}')\n",
    "\n",
    "\n",
    "\n",
    "    return teacher_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a2cf628-4eff-4435-bb0c-e0cd329326a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# teacher_model = train_teacher(num_epochs=1, device=device, teacher_model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d647ed9-9221-4a97-ae7e-f090f3dcd39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def train_step(teacher_model, student_model, optimizer, divergence_loss_fn, temp, alpha, epoch, device):\n",
    "#     train_dataset = TranslationDataset(file_path='data/ko2en_travel_1_training_Bleu_Grouge.json',\n",
    "#                         mode='train',\n",
    "#                         tokenizer=tokenizer)\n",
    "\n",
    "#     train_dataloader = DataLoader(\n",
    "#             dataset=train_dataset, \n",
    "#             batch_size=2,\n",
    "#             shuffle=True,\n",
    "#             #num_workers=1,\n",
    "#             collate_fn=collate_fn_translation\n",
    "#         )\n",
    "    \n",
    "    dataset = TranslationDataset(file_path='data/sns100.csv',\n",
    "                                        tokenizer=tokenizer)\n",
    "\n",
    "    dataloader = DataLoader(\n",
    "                            dataset=dataset, \n",
    "                            batch_size=1,\n",
    "                            shuffle=True,\n",
    "                            #num_workers=1,\n",
    "                            collate_fn=collate_fn_translation\n",
    "                        )\n",
    "    losses = []\n",
    "    teacher_ppls = []\n",
    "    student_ppls = []\n",
    "\n",
    "    for batch in dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "        teacher_model.eval()\n",
    "        student_model.train()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            teacher_outputs = teacher_model(**batch)\n",
    "            teacher_logits = teacher_outputs.logits\n",
    "            teacher_ppls.append(torch.exp(teacher_outputs.loss))\n",
    "                \n",
    "        student_outputs = student_model(**batch)\n",
    "        student_loss = student_outputs.loss\n",
    "        student_logits = student_outputs.logits\n",
    "        student_ppls.append(torch.exp(student_loss))\n",
    "\n",
    "        max_vocab_size = teacher_logits.shape[-1]\n",
    "        distillation_loss = divergence_loss_fn(\n",
    "                                                F.log_softmax(student_logits.view(-1,max_vocab_size) / temp, dim=1),\n",
    "                                                F.softmax(teacher_logits.view(-1, max_vocab_size) / temp, dim=1)\n",
    "                                            )\n",
    "        loss = alpha * student_loss + (1 - alpha) * distillation_loss\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "    \n",
    "    avg_loss = sum(losses) / len(losses)\n",
    "    teacher_avg_ppls = sum(teacher_ppls) / len(teacher_ppls)\n",
    "    student_avg_ppls = sum(student_ppls) / len(student_ppls)\n",
    "\n",
    "    return avg_loss, teacher_avg_ppls, student_avg_ppls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1193fe64-f641-4dcb-b44d-0cbd5989c9ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "def main(teacher_model, student_model, tokenizer, device, temp=7, alpha=0.3):\n",
    "    # teacher_model = teacher_model.to(device)\n",
    "    # student_model = student_model.to(device)\n",
    "    # student_loss_fn = nn.CrossEntropyLoss()\n",
    "    divergence_loss_fn = nn.KLDivLoss(reduction='batchmean')\n",
    "    optimizer = torch.optim.Adam(student_model.parameters(), lr=1e-3)\n",
    "\n",
    "    epochs = 10\n",
    "    for epoch in range(epochs):\n",
    "        # loss = train_step(teacher_model, student_model, optimizer, student_loss_fn, divergence_loss_fn, temp, alpha, epoch, device)\n",
    "        # acc = check_accuracy(test_loader, student, device)\n",
    "        loss, teacher_ppl, student_ppl = train_step(teacher_model, student_model, optimizer, divergence_loss_fn, temp, alpha, epoch, device)\n",
    "        bleu_score = evaluate(student_model, tokenizer, device)\n",
    "        print(f'Loss : {loss:.2f}\\tTeacher_ppl : {teacher_ppl:.2f}\\tStudent_ppl : {student_ppl:.2f}\\tBleu_score : {bleu_score:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "475088f0-cd5d-4984-9a92-182a3d0cc072",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 100/100 [00:12<00:00,  7.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss : 2.27\tTeacher_ppl : 12.13\tStudent_ppl : 6605.48\tBleu_score : 0.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 100/100 [00:10<00:00,  9.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss : 1.65\tTeacher_ppl : 12.13\tStudent_ppl : 324.76\tBleu_score : 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 100/100 [01:16<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss : 1.46\tTeacher_ppl : 12.13\tStudent_ppl : 185.73\tBleu_score : 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 100/100 [00:45<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss : 1.35\tTeacher_ppl : 12.13\tStudent_ppl : 194.93\tBleu_score : 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 100/100 [00:56<00:00,  1.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss : 1.23\tTeacher_ppl : 12.13\tStudent_ppl : 107.02\tBleu_score : 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 100/100 [01:40<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss : 1.15\tTeacher_ppl : 12.13\tStudent_ppl : 73.46\tBleu_score : 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 100/100 [00:03<00:00, 29.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss : 1.05\tTeacher_ppl : 12.13\tStudent_ppl : 288.92\tBleu_score : 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 100/100 [01:46<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss : 0.93\tTeacher_ppl : 12.13\tStudent_ppl : 39.55\tBleu_score : 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 100/100 [00:38<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss : 0.87\tTeacher_ppl : 12.13\tStudent_ppl : 25.27\tBleu_score : 0.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 100/100 [00:06<00:00, 14.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss : 0.88\tTeacher_ppl : 12.13\tStudent_ppl : 51.13\tBleu_score : 0.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "main(teacher_model, student_model, tokenizer, device, temp=7, alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce42f34b-6e31-4f1f-ae08-3fe8cbcf467e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
